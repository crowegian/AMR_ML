{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn.linear_model import LassoCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPath = \"../../data/MLData/inst_feature_matrix_non_syn_20180329.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataPath)\n",
    "df = df.set_index(\"isolate\")\n",
    "X_df = df.drop(labels = [\"pbr_res\"], axis = 1)\n",
    "X = X_df.values\n",
    "Y_df = df[\"pbr_res\"]\n",
    "Y = Y_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection union\n",
    "# unused right now\n",
    "features = []\n",
    "# features.append(('pca', PCA(n_components=3)))\n",
    "# features.append(('select_best', SelectKBest(k=6)))\n",
    "# clf = LassoCV()\n",
    "\n",
    "# Set a minimum threshold of 0.25\n",
    "features = [(\"linSVC_dimReduction\", SelectFromModel(LinearSVC(), 0.25))]\n",
    "# features.append(SelectFromModel(LinearSVC(C=0.01, penalty=\"l1\", dual=False),\n",
    "#                                 threshold=0.25, prefit = False))\n",
    "feature_union = FeatureUnion(features)\n",
    "featureSelectionParamGrid = {} # TODO implement feature selection for feature selection.\n",
    "modelDict = {}\n",
    "cv = 10\n",
    "# TODO when you perform CV with this stuff consider doing memory option stuff\n",
    "scoring = [\"accuracy\", \"f1\", \"precision\", \"recall\"]\n",
    "importantMetric = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create pipeline for logisttic Regression\n",
    "estimators_LR = []\n",
    "estimators_LR.append(('feature_union', feature_union))\n",
    "estimators_LR.append(('logistic', LogisticRegression()))\n",
    "# estimators.append(models)\n",
    "paramGrid_LR = [\n",
    "    {\n",
    "        \"logistic__penalty\": ['l1', 'l2'],\n",
    "        \"logistic__C\": [1, 10, 100, 1000]\n",
    "    }\n",
    "]\n",
    "modelDict[\"logistic\"] = {\"pipe\": Pipeline(estimators_LR),\n",
    "                         \"params\": paramGrid_LR}\n",
    "modelDict[\"logistic\"][\"gridcv\"] = GridSearchCV(estimator = modelDict[\"logistic\"][\"pipe\"],\n",
    "                         param_grid = modelDict[\"logistic\"][\"params\"],\n",
    "                         cv = cv, n_jobs = 1,\n",
    "                         scoring = scoring, refit = importantMetric)\n",
    "# TODO understand how linearSVC works with these parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create pipeline for RF\n",
    "estimators_RF = []\n",
    "estimators_RF.append(('feature_union', feature_union))\n",
    "estimators_RF.append(('RFC', RandomForestClassifier()))\n",
    "# estimators.append(models)\n",
    "paramGrid_RF = [\n",
    "    {\n",
    "        \"RFC__n_estimators\": [5, 10, 15, 20],# second most important feature to tune. First\n",
    "        # is max number of feats.\n",
    "        \"RFC__max_features\": [\"sqrt\", \"log2\", 0.5],# we have lots of possibly dumb\n",
    "        # features so it might be good to use lower numbers here\n",
    "        \"RFC__max_depth\": [None],# still need to understand if deeper trees are better.\n",
    "        \"RFC__criterion\":[\"gini\"],# no idea if this will make a difference. can check\n",
    "    }\n",
    "]\n",
    "\n",
    "modelDict[\"randomForest\"] = {\"pipe\": Pipeline(estimators_RF),\n",
    "                             \"params\": paramGrid_RF}\n",
    "modelDict[\"randomForest\"][\"gridcv\"] = GridSearchCV(estimator = modelDict[\"randomForest\"][\"pipe\"],\n",
    "                       param_grid = modelDict[\"randomForest\"][\"params\"],\n",
    "                       cv = cv, n_jobs = 1,\n",
    "                       scoring = scoring, refit = importantMetric)\n",
    "#TODO is it better to build RF trees to purity and prune?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create pipeline for SVC\n",
    "estimators_SVC = []\n",
    "estimators_SVC.append(('feature_union', feature_union))\n",
    "estimators_SVC.append(('SVC', SVC()))\n",
    "# estimators.append(models)\n",
    "paramGrid_SVC = [\n",
    "    {\n",
    "        \"SVC__penalty\": ['l1', 'l2'],\n",
    "        \"SVC__C\": [1, 10, 100, 1000]\n",
    "    }\n",
    "]\n",
    "modelDict[\"SVC\"] = {\"pipe\":Pipeline(estimators_SVC),\n",
    "                    \"params\": paramGrid_SVC}\n",
    "modelDict[\"SVC\"][\"gridcv\"] = GridSearchCV(estimator = modelDict[\"SVC\"][\"pipe\"],\n",
    "                       param_grid = modelDict[\"SVC\"][\"params\"],\n",
    "                       cv = cv, n_jobs = 1,\n",
    "                       scoring = scoring, refit = importantMetric)\n",
    "\n",
    "\n",
    "\n",
    "# create pipeline for GBTC\n",
    "estimators_GBTC = []\n",
    "estimators_GBTC.append(('feature_union', feature_union))\n",
    "estimators_GBTC.append(('GBTC', GradientBoostingClassifier()))\n",
    "# estimators.append(models)\n",
    "paramGrid_GBTC = [\n",
    "    {\n",
    "        \"GBTC__learning_rate\": [0.001, 0.01, 0.1],\n",
    "        \"GBTC__n_estimators\": [50, 100, 200, 300, 400, 500],\n",
    "        \"GBTC__max_depth\": [1, 3, 5, 10, 12]\n",
    "    }\n",
    "]\n",
    "modelDict[\"GBTC\"] = {\"pipe\": Pipeline(estimators_GBTC),\n",
    "                     \"params\": paramGrid_GBTC}\n",
    "modelDict[\"GBTC\"][\"gridcv\"] = GridSearchCV(estimator = modelDict[\"GBTC\"][\"pipe\"],\n",
    "                       param_grid = modelDict[\"GBTC\"][\"params\"],\n",
    "                       cv = cv, n_jobs = 1,\n",
    "                       scoring = scoring, refit = importantMetric)\n",
    "# modelDict[\"gradientBosting\"] = Pipeline(estimators_GBTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "estimators_SVC = []\n",
    "estimators_SVC.append(('feature_union', feature_union))\n",
    "estimators_SVC.append(('SVC', SVC()))\n",
    "# estimators.append(models)\n",
    "paramGrid_SVC = [\n",
    "    {\n",
    "        \"SVC__penalty\": ['l1', 'l2'],\n",
    "        \"SVC__C\": [1, 10, 100, 1000]\n",
    "    }\n",
    "]\n",
    "modelDict[\"SVC\"] = {\"pipe\":Pipeline(estimators_SVC),\n",
    "                    \"params\": paramGrid_SVC}\n",
    "modelDict[\"SVC\"][\"gridcv\"] = GridSearchCV(estimator = modelDict[\"SVC\"][\"pipe\"], cv = cv,\n",
    "                       param_grid = modelDict[\"SVC\"][\"params\"], n_jobs = 1)\n",
    "# modelDict[\"SVC\"] = Pipeline(estimators_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "estimators_GBTC = []\n",
    "estimators_GBTC.append(('feature_union', feature_union))\n",
    "estimators_GBTC.append(('GBTC', GradientBoostingClassifier()))\n",
    "# estimators.append(models)\n",
    "paramGrid_GBTC = [\n",
    "    {\n",
    "        \"GBTC__learning_rate\": [0.001, 0.01, 0.1],\n",
    "        \"GBTC__n_estimators\": [50, 100, 200, 300, 400, 500],\n",
    "        \"GBTC__max_depth\": [1, 3, 5, 10, 12]\n",
    "    }\n",
    "]\n",
    "modelDict[\"GBTC\"] = [Pipeline(estimators_GBTC), paramGrid_GBTC]\n",
    "gridcv_LR = GridSearchCV(estimator = modelDict[\"GBTC\"][0], cv = cv,\n",
    "                       param_grid = modelDict[\"GBTC\"][1], n_jobs = 1)\n",
    "modelDict[\"gradientBosting\"] = Pipeline(estimators_GBTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for logistic\n",
      "{'accuracy': 0.55999999999999994, 'f1': 0.50657429607429605, 'precision': 0.61407661782661782, 'recall': 0.51237412913883507}\n",
      "\n",
      "\n",
      "Metrics for randomForest\n",
      "{'accuracy': 0.53499999999999992, 'f1': 0.47718709972744716, 'precision': 0.5924009324009325, 'recall': 0.46138116785175615}\n",
      "\n",
      "\n",
      "Metrics for SVC\n",
      "{'accuracy': 0.35999999999999999, 'f1': 0.504621863504922, 'precision': 0.49444444444444435, 'recall': 0.80264705882352949}\n",
      "\n",
      "\n",
      "Metrics for gradientBosting\n",
      "{'accuracy': 0.55999999999999994, 'f1': 0.49615496098104794, 'precision': 0.54168831168831166, 'recall': 0.49498383968972204}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "scoring = [\"accuracy\", \"f1\", \"precision\", \"recall\"]\n",
    "metrics = {}\n",
    "for modelName, model in modelDict.items():\n",
    "#     print(model)\n",
    "    results = cross_validate(model, X, Y, cv=kfold,  scoring=scoring, )\n",
    "#     results = cross_val_score(estimator=model,\n",
    "#                               X=features,\n",
    "#                               y=labels,\n",
    "#                               cv=kfold,\n",
    "#                               scoring=scoring)\n",
    "#     break\n",
    "    for idx, metric in enumerate(scoring):\n",
    "        metrics[metric] = results[\"test_\"+metric].mean()\n",
    "#     accMean = results[\"test_\"+scoring[idx]].mean()\n",
    "    print(\"Metrics for {}\".format(modelName))\n",
    "    print(metrics)\n",
    "    print(\"\\n\")\n",
    "#     break\n",
    "# kfold = KFold(n_splits=10, random_state=seed)\n",
    "# results = cross_val_score(model, X, Y, cv=kfold)\n",
    "# print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.08118463,  0.07761335,  0.08058453,  0.07894659,  0.07932329,\n",
       "         0.07868505,  0.08367991,  0.08803058,  0.08775806,  0.08080649]),\n",
       " 'score_time': array([ 0.00208187,  0.00207233,  0.00208974,  0.00207472,  0.00207257,\n",
       "         0.00202703,  0.00224113,  0.00220537,  0.00201702,  0.00197744]),\n",
       " 'test_accuracy': array([ 0.8 ,  0.35,  0.6 ,  0.35,  0.65,  0.55,  0.6 ,  0.45,  0.5 ,  0.75]),\n",
       " 'test_f1': array([ 0.85714286,  0.48      ,  0.75      ,  0.51851852,  0.69565217,\n",
       "         0.52631579,  0.33333333,  0.26666667,  0.        ,  0.61538462]),\n",
       " 'test_precision': array([ 0.75      ,  0.4       ,  0.8       ,  1.        ,  0.8       ,\n",
       "         0.5       ,  0.4       ,  0.25      ,  0.        ,  0.57142857]),\n",
       " 'test_recall': array([ 1.        ,  0.6       ,  0.70588235,  0.35      ,  0.61538462,\n",
       "         0.55555556,  0.28571429,  0.28571429,  0.        ,  0.66666667]),\n",
       " 'train_accuracy': array([ 0.88888889,  0.86666667,  0.88333333,  0.88333333,  0.87777778,\n",
       "         0.86666667,  0.89444444,  0.91666667,  0.88888889,  0.89444444]),\n",
       " 'train_f1': array([ 0.89130435,  0.86956522,  0.87573964,  0.87272727,  0.87777778,\n",
       "         0.86956522,  0.9035533 ,  0.92307692,  0.89690722,  0.9025641 ]),\n",
       " 'train_precision': array([ 0.92134831,  0.91954023,  0.93670886,  0.92307692,  0.91860465,\n",
       "         0.93023256,  0.91752577,  0.94736842,  0.93548387,  0.93617021]),\n",
       " 'train_recall': array([ 0.86315789,  0.82474227,  0.82222222,  0.82758621,  0.84042553,\n",
       "         0.81632653,  0.89      ,  0.9       ,  0.86138614,  0.87128713])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75, 0.35, 0.7 , 0.6 , 0.4 , 0.55, 0.65, 0.5 , 0.7 , 0.85])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5900000000000001\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline(estimators_GBTC)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('GBTC', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.535"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVC': Pipeline(memory=None,\n",
       "      steps=[('SVC', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False))]), 'gradientBosting': Pipeline(memory=None,\n",
       "      steps=[('GBTC', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "               min_samples_leaf=1, min_samples_split=2,\n",
       "               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "               presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "               warm_start=False))]), 'logistic': Pipeline(memory=None,\n",
       "      steps=[('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False))]), 'randomForest': Pipeline(memory=None,\n",
       "      steps=[('RFC', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False))])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
