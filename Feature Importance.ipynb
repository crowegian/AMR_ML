{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Extraction\n",
    "This notebook lets you look at the feature importance for the best model in each model class for a given dataset. You'll have to be sure that the modelDictPath supplied was trained on the dataset you want to look at. This is because feature names are not stored in the model, so you need the **original** dataset used to train the model in order to extract human readable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDictPath = \"data/featureImportanceTestData/modelDictMultiDataRun_datasets_1_2_3_7_20190722.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(modelDictPath, \"rb\") as pklFile:\n",
    "    allDataModelDict = pickle.load(pklFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "modelName = \"SVC\"\n",
    "modelDict = allDataModelDict[\"dataset_1_\"][modelName]\n",
    "dataPath = \"data/featureImportanceTestData/dataset_1_full.csv\"\n",
    "bestModel = modelDict[\"gridcv\"].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_coefficients(classifier, feature_names, top_features=10): \n",
    "#     coef = classifier.best_estimator_.coef_.ravel()\n",
    "#     top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "#     top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "#     top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "#     # create plot\n",
    "#     sb.set_context(\"poster\")\n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     plt.title(\"Feature Importances (Support Vector Classifier)\")\n",
    "#     colors = ['crimson' if c < 0 else 'cornflowerblue' for c in coef[top_coefficients]]\n",
    "#     plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "#     feature_names = np.array(feature_names)\n",
    "#     plt.xticks(np.arange(0, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right') plt.show()\n",
    "#     np.asarray(feature_names)[top_positive_coefficients]\n",
    "\n",
    "#     plot_coefficients(svm_model, list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "coef_ is only available when using a linear kernel",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-36061eec2270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbestModelParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/AMR_ML/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mcoef_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcoef_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             raise AttributeError('coef_ is only available when using a '\n\u001b[0m\u001b[1;32m    481\u001b[0m                                  'linear kernel')\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: coef_ is only available when using a linear kernel"
     ]
    }
   ],
   "source": [
    "# bestModelParams.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance logistic\n",
      "2277 features before feature selection\n",
      "661 features passed to this model\n",
      "661 unique features passed to this model\n",
      "203 features given feature importance above 0\n",
      "\n",
      "SANITY CHECK. This is the best model being used. Please be sure that The parameters match up with the model you specified. Sometimes an old model Can be used by accident if the kernel is not restarted\n",
      "\n",
      " LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "human readable feature importance\n",
      "Feature mgrB coefficient/importance 20.096792636473804\n",
      "\n",
      "Feature KP0228_02051 coefficient/importance 16.780148994355134\n",
      "\n",
      "Feature KP0228_03719 coefficient/importance 15.044282982810538\n",
      "\n",
      "Feature KP0228_00159 coefficient/importance -14.794937432144755\n",
      "\n",
      "Feature KP0228_04120 coefficient/importance 14.25906212636767\n",
      "\n",
      "Feature KP0228_04079 coefficient/importance 13.615277125936435\n",
      "\n",
      "Feature KP0228_01191 coefficient/importance -13.250081288477007\n",
      "\n",
      "Feature KP0228_03852 coefficient/importance -13.061903282336951\n",
      "\n",
      "Feature KP0228_00250 coefficient/importance -12.702913142216595\n",
      "\n",
      "Feature KP0228_00231 coefficient/importance 12.480885373345659\n",
      "\n",
      "Feature KP0228_04054 coefficient/importance 12.412976149185031\n",
      "\n",
      "Feature KP0228_03775 coefficient/importance -12.344486449884771\n",
      "\n",
      "Feature KP0228_01648 coefficient/importance 12.059174551541314\n",
      "\n",
      "Feature KP0228_03994 coefficient/importance 11.391855124738898\n",
      "\n",
      "Feature KP0228_03168 coefficient/importance -10.945382544331428\n",
      "\n",
      "Feature KP0228_04594 coefficient/importance 10.768923990846394\n",
      "\n",
      "Feature KP0228_03382 coefficient/importance -10.506466349920101\n",
      "\n",
      "Feature KP0228_01223 coefficient/importance 10.241681294787082\n",
      "\n",
      "Feature KP0228_04429 coefficient/importance -10.207391452485144\n",
      "\n",
      "Feature KP0228_04647 coefficient/importance -9.889848714894582\n",
      "\n",
      "Feature KP0228_00591 coefficient/importance 9.679951781058403\n",
      "\n",
      "Feature KP0228_00700 coefficient/importance -9.336872593419118\n",
      "\n",
      "Feature KP0228_05018 coefficient/importance 8.568195358692085\n",
      "\n",
      "Feature KP0228_00230 coefficient/importance -8.303072452955409\n",
      "\n",
      "Feature KP0228_04175 coefficient/importance 8.30041650776661\n",
      "\n",
      "Feature KP0228_00063 coefficient/importance 7.52266940784179\n",
      "\n",
      "Feature KP0228_02747 coefficient/importance -7.347975528837725\n",
      "\n",
      "Feature KP0228_00089 coefficient/importance 7.18636111295361\n",
      "\n",
      "Feature KP0228_00935 coefficient/importance -6.95647844825859\n",
      "\n",
      "Feature KP0228_01623 coefficient/importance -6.464227033539828\n",
      "\n",
      "Feature KP0228_04384 coefficient/importance -6.375683862621158\n",
      "\n",
      "Feature KP0228_01448 coefficient/importance -5.995076215667183\n",
      "\n",
      "Feature KP0228_04994 coefficient/importance -5.848607558413882\n",
      "\n",
      "Feature KP0228_04845 coefficient/importance 5.71293265822936\n",
      "\n",
      "Feature KP0228_03378 coefficient/importance 5.523923259959511\n",
      "\n",
      "Feature KP0228_03229 coefficient/importance 5.410664543428924\n",
      "\n",
      "Feature KP0228_00943 coefficient/importance 5.365479311376306\n",
      "\n",
      "Feature KP0228_04612 coefficient/importance -5.093367127580888\n",
      "\n",
      "Feature KP0228_01206 coefficient/importance -5.037978864213736\n",
      "\n",
      "Feature KP0228_02039 coefficient/importance -5.00506672196372\n",
      "\n",
      "Feature KP0228_02041 coefficient/importance -4.87486152817607\n",
      "\n",
      "Feature KP0228_02534 coefficient/importance 4.865412163146921\n",
      "\n",
      "Feature KP0228_03718 coefficient/importance 4.79278876799354\n",
      "\n",
      "Feature KP0228_00304 coefficient/importance -4.738893701312986\n",
      "\n",
      "Feature KP0228_04293 coefficient/importance -4.300242800984468\n",
      "\n",
      "Feature KP0228_02212 coefficient/importance 4.243358707162233\n",
      "\n",
      "Feature KP0228_04468 coefficient/importance 4.189080872944728\n",
      "\n",
      "Feature KP0228_04206 coefficient/importance 4.089892453598774\n",
      "\n",
      "Feature KP0228_00239 coefficient/importance 4.085399593815444\n",
      "\n",
      "Feature KP0228_00179 coefficient/importance 4.050410657238713\n",
      "\n",
      "Feature KP0228_03154 coefficient/importance -3.956593195947193\n",
      "\n",
      "Feature KP0228_03166 coefficient/importance -3.871666146308956\n",
      "\n",
      "Feature KP0228_04904 coefficient/importance 3.8610328760488972\n",
      "\n",
      "Feature KP0228_02409 coefficient/importance 3.721591433414904\n",
      "\n",
      "Feature KP0228_03875 coefficient/importance -3.7079309929357467\n",
      "\n",
      "Feature KP0228_03370 coefficient/importance 3.6177148537969344\n",
      "\n",
      "Feature KP0228_03995 coefficient/importance -3.6126035294542063\n",
      "\n",
      "Feature KP0228_01881 coefficient/importance 3.566998862383659\n",
      "\n",
      "Feature KP0228_04064 coefficient/importance -3.540897390324735\n",
      "\n",
      "Feature KP0228_02221 coefficient/importance 3.5055225868003137\n",
      "\n",
      "Feature KP0228_03273 coefficient/importance -3.4858391570324683\n",
      "\n",
      "Feature KP0228_04007 coefficient/importance -3.4538069668411135\n",
      "\n",
      "Feature KP0228_00733 coefficient/importance -3.4283916611550853\n",
      "\n",
      "Feature KP0228_02559 coefficient/importance 3.327079253597284\n",
      "\n",
      "Feature KP0228_00590 coefficient/importance 3.280444057286238\n",
      "\n",
      "Feature KP0228_02317 coefficient/importance -3.251188144072955\n",
      "\n",
      "Feature KP0228_03593 coefficient/importance -3.2322323851020536\n",
      "\n",
      "Feature KP0228_00827 coefficient/importance 3.1084167891851906\n",
      "\n",
      "Feature KP0228_01637 coefficient/importance 3.016083437454786\n",
      "\n",
      "Feature KP0228_04835 coefficient/importance 2.992937131446031\n",
      "\n",
      "Feature KP0228_00801 coefficient/importance 2.8265828368003\n",
      "\n",
      "Feature KP0228_00799 coefficient/importance -2.807133212278619\n",
      "\n",
      "Feature KP0228_00398 coefficient/importance -2.791426313414855\n",
      "\n",
      "Feature KP0228_02388 coefficient/importance -2.73601234442038\n",
      "\n",
      "Feature KP0228_00885 coefficient/importance -2.6750440587120528\n",
      "\n",
      "Feature KP0228_00787 coefficient/importance 2.529363443438597\n",
      "\n",
      "Feature KP0228_03380 coefficient/importance -2.3732133937521387\n",
      "\n",
      "Feature KP0228_05019 coefficient/importance 2.2199954646708977\n",
      "\n",
      "Feature KP0228_04292 coefficient/importance -2.1873759497970022\n",
      "\n",
      "Feature KP0228_03486 coefficient/importance 2.1050004422152444\n",
      "\n",
      "Feature KP0228_00390 coefficient/importance 2.100843227980202\n",
      "\n",
      "Feature KP0228_01639 coefficient/importance 2.0865302481880392\n",
      "\n",
      "Feature KP0228_00798 coefficient/importance 2.037028604342625\n",
      "\n",
      "Feature KP0228_03901 coefficient/importance 2.0068623416848785\n",
      "\n",
      "Feature KP0228_04305 coefficient/importance 1.9936733941861622\n",
      "\n",
      "Feature KP0228_00813 coefficient/importance 1.9753454132502877\n",
      "\n",
      "Feature KP0228_03372 coefficient/importance -1.9331528057498069\n",
      "\n",
      "Feature KP0228_04532 coefficient/importance -1.8705942348230222\n",
      "\n",
      "Feature KP0228_04168 coefficient/importance 1.8543574386590953\n",
      "\n",
      "Feature KP0228_00228 coefficient/importance -1.8395603661371833\n",
      "\n",
      "Feature KP0228_03419 coefficient/importance 1.8311458846172812\n",
      "\n",
      "Feature KP0228_00318 coefficient/importance -1.8056901836896746\n",
      "\n",
      "Feature KP0228_00945 coefficient/importance 1.7919262385214378\n",
      "\n",
      "Feature KP0228_02672 coefficient/importance 1.7606811116097378\n",
      "\n",
      "Feature KP0228_03173 coefficient/importance -1.7529526367289492\n",
      "\n",
      "Feature KP0228_00995 coefficient/importance 1.6976052426905506\n",
      "\n",
      "Feature KP0228_00656 coefficient/importance 1.6859452240032122\n",
      "\n",
      "Feature KP0228_04911 coefficient/importance -1.6820529171418068\n",
      "\n",
      "Feature KP0228_03192 coefficient/importance -1.6616486295279926\n",
      "\n",
      "Feature KP0228_00302 coefficient/importance -1.6474708064014834\n",
      "\n",
      "Feature KP0228_04943 coefficient/importance -1.6473707604259502\n",
      "\n",
      "Feature KP0228_00229 coefficient/importance 1.589600376169998\n",
      "\n",
      "Feature KP0228_04701 coefficient/importance -1.58664110061904\n",
      "\n",
      "Feature KP0228_04315 coefficient/importance 1.5772941949696753\n",
      "\n",
      "Feature KP0228_04573 coefficient/importance 1.5676313141786142\n",
      "\n",
      "Feature KP0228_01052 coefficient/importance 1.5319060641802749\n",
      "\n",
      "Feature KP0228_00384 coefficient/importance 1.4785137519008147\n",
      "\n",
      "Feature KP0228_02442 coefficient/importance 1.4465415030422897\n",
      "\n",
      "Feature KP0228_00831 coefficient/importance -1.4458322365971792\n",
      "\n",
      "Feature KP0228_00256 coefficient/importance 1.4224990381108955\n",
      "\n",
      "Feature KP0228_02223 coefficient/importance -1.4210406195147027\n",
      "\n",
      "Feature KP0228_03771 coefficient/importance -1.3970245748497923\n",
      "\n",
      "Feature KP0228_00828 coefficient/importance 1.3824623987300038\n",
      "\n",
      "Feature KP0228_04432 coefficient/importance 1.3684045564799838\n",
      "\n",
      "Feature KP0228_02357 coefficient/importance -1.3218756665728255\n",
      "\n",
      "Feature KP0228_04298 coefficient/importance -1.2926564786566428\n",
      "\n",
      "Feature KP0228_02342 coefficient/importance 1.2876254926545898\n",
      "\n",
      "Feature KP0228_03233 coefficient/importance -1.2596905170949426\n",
      "\n",
      "Feature KP0228_00227 coefficient/importance -1.2483195168753585\n",
      "\n",
      "Feature KP0228_02890 coefficient/importance 1.2123393929114477\n",
      "\n",
      "Feature KP0228_03241 coefficient/importance -1.1935228535455609\n",
      "\n",
      "Feature KP0228_04031 coefficient/importance 1.1353340914489995\n",
      "\n",
      "Feature KP0228_02674 coefficient/importance -1.1311370320010696\n",
      "\n",
      "Feature KP0228_00134 coefficient/importance -1.1079092955556298\n",
      "\n",
      "Feature KP0228_00532 coefficient/importance 1.0889848028625009\n",
      "\n",
      "Feature KP0228_02477 coefficient/importance -1.0583437490084007\n",
      "\n",
      "Feature KP0228_01412 coefficient/importance -1.0580280287997064\n",
      "\n",
      "Feature KP0228_03536 coefficient/importance 0.9966993304599695\n",
      "\n",
      "Feature KP0228_00864 coefficient/importance 0.9902920454462548\n",
      "\n",
      "Feature KP0228_03164 coefficient/importance -0.970143099159191\n",
      "\n",
      "Feature KP0228_02232 coefficient/importance 0.8772720457087234\n",
      "\n",
      "Feature KP0228_00838 coefficient/importance -0.865616489495923\n",
      "\n",
      "Feature KP0228_03004 coefficient/importance 0.8067829355152363\n",
      "\n",
      "Feature KP0228_04440 coefficient/importance -0.800255741873549\n",
      "\n",
      "Feature KP0228_03346 coefficient/importance -0.7829417618616795\n",
      "\n",
      "Feature KP0228_03625 coefficient/importance -0.769769504115931\n",
      "\n",
      "Feature KP0228_03109 coefficient/importance 0.7667948822875362\n",
      "\n",
      "Feature KP0228_00108 coefficient/importance -0.7638372434056165\n",
      "\n",
      "Feature KP0228_00755 coefficient/importance -0.7631809451707681\n",
      "\n",
      "Feature KP0228_04113 coefficient/importance -0.7340625991206824\n",
      "\n",
      "Feature KP0228_01339 coefficient/importance -0.7222012930181376\n",
      "\n",
      "Feature KP0228_05223 coefficient/importance 0.7169146095185354\n",
      "\n",
      "Feature KP0228_03556 coefficient/importance 0.6905786706669171\n",
      "\n",
      "Feature KP0228_00841 coefficient/importance 0.6762571113651679\n",
      "\n",
      "Feature KP0228_00791 coefficient/importance -0.6133463456427706\n",
      "\n",
      "Feature KP0228_02065 coefficient/importance -0.611593152062572\n",
      "\n",
      "Feature KP0228_04446 coefficient/importance -0.6029124396011797\n",
      "\n",
      "Feature KP0228_04568 coefficient/importance -0.5585842095918472\n",
      "\n",
      "Feature KP0228_00446 coefficient/importance 0.5575039987512328\n",
      "\n",
      "Feature KP0228_00367 coefficient/importance -0.5410154844173326\n",
      "\n",
      "Feature KP0228_00074 coefficient/importance -0.5254058312248215\n",
      "\n",
      "Feature KP0228_03020 coefficient/importance -0.522106206046189\n",
      "\n",
      "Feature KP0228_03428 coefficient/importance 0.5067570865544524\n",
      "\n",
      "Feature KP0228_03031 coefficient/importance -0.5058038733740585\n",
      "\n",
      "Feature KP0228_00386 coefficient/importance 0.4934047055681713\n",
      "\n",
      "Feature KP0228_00891 coefficient/importance 0.4927004361511349\n",
      "\n",
      "Feature KP0228_04388 coefficient/importance -0.4723294562895025\n",
      "\n",
      "Feature KP0228_02626 coefficient/importance 0.4457878156098286\n",
      "\n",
      "Feature KP0228_00823 coefficient/importance 0.4304763623807961\n",
      "\n",
      "Feature KP0228_00963 coefficient/importance 0.428675443655432\n",
      "\n",
      "Feature KP0228_05291 coefficient/importance -0.42009289124158383\n",
      "\n",
      "Feature KP0228_00652 coefficient/importance 0.4111184232657293\n",
      "\n",
      "Feature KP0228_03596 coefficient/importance 0.39131636201485\n",
      "\n",
      "Feature KP0228_00704 coefficient/importance -0.3846511441191855\n",
      "\n",
      "Feature KP0228_03445 coefficient/importance -0.3842965782063716\n",
      "\n",
      "Feature KP0228_03364 coefficient/importance -0.37413089663297505\n",
      "\n",
      "Feature KP0228_03073 coefficient/importance 0.366245693423325\n",
      "\n",
      "Feature KP0228_03517 coefficient/importance 0.3535961515339982\n",
      "\n",
      "Feature KP0228_04395 coefficient/importance -0.3499990203742801\n",
      "\n",
      "Feature KP0228_03361 coefficient/importance 0.32199175060839197\n",
      "\n",
      "Feature KP0228_04302 coefficient/importance -0.3162982391075818\n",
      "\n",
      "Feature KP0228_04490 coefficient/importance 0.3086879609580708\n",
      "\n",
      "Feature KP0228_03762 coefficient/importance 0.30196729649151727\n",
      "\n",
      "Feature KP0228_04130 coefficient/importance 0.2893800675844291\n",
      "\n",
      "Feature KP0228_00994 coefficient/importance 0.2844978883278437\n",
      "\n",
      "Feature KP0228_01233 coefficient/importance 0.27838694513999146\n",
      "\n",
      "Feature KP0228_01656 coefficient/importance 0.2756653618770933\n",
      "\n",
      "Feature KP0228_05205 coefficient/importance 0.26154195355857224\n",
      "\n",
      "Feature KP0228_01089 coefficient/importance -0.23357698374538494\n",
      "\n",
      "Feature KP0228_04207 coefficient/importance -0.20178762552069499\n",
      "\n",
      "Feature KP0228_05045 coefficient/importance -0.18012991274011342\n",
      "\n",
      "Feature KP0228_04196 coefficient/importance 0.17357661550421644\n",
      "\n",
      "Feature KP0228_02616 coefficient/importance 0.1598359822737318\n",
      "\n",
      "Feature KP0228_00770 coefficient/importance -0.15970464831516032\n",
      "\n",
      "Feature KP0228_03052 coefficient/importance 0.15712484115142447\n",
      "\n",
      "Feature KP0228_04336 coefficient/importance -0.13942934729368062\n",
      "\n",
      "Feature KP0228_04579 coefficient/importance -0.1354828710856843\n",
      "\n",
      "Feature KP0228_00806 coefficient/importance -0.13022645025264448\n",
      "\n",
      "Feature KP0228_02745 coefficient/importance 0.12222779349816096\n",
      "\n",
      "Feature KP0228_01268 coefficient/importance 0.09651237853974191\n",
      "\n",
      "Feature KP0228_02541 coefficient/importance -0.09616693075072842\n",
      "\n",
      "Feature KP0228_00740 coefficient/importance -0.09061275423371412\n",
      "\n",
      "Feature KP0228_04033 coefficient/importance -0.08976501431583246\n",
      "\n",
      "Feature KP0228_02598 coefficient/importance 0.0791931666594127\n",
      "\n",
      "Feature KP0228_04367 coefficient/importance 0.07138235023275641\n",
      "\n",
      "Feature KP0228_05090 coefficient/importance -0.06176096751183491\n",
      "\n",
      "Feature KP0228_04882 coefficient/importance -0.06014065874540839\n",
      "\n",
      "Feature KP0228_02213 coefficient/importance 0.04829798303830036\n",
      "\n",
      "Feature KP0228_03914 coefficient/importance 0.04311581383411741\n",
      "\n",
      "Feature KP0228_00923 coefficient/importance -0.027465728857459064\n",
      "\n",
      "Feature KP0228_00941 coefficient/importance -0.024817414226194042\n",
      "\n",
      "Feature KP0228_02685 coefficient/importance 0.003246910407289766\n",
      "\n",
      "Feature KP0228_03920 coefficient/importance -0.00017987216083136402\n",
      "\n",
      "Printing feature importance so it can be copied into a csv file\n",
      "featureName,importanceMetric\n",
      "mgrB,20.096792636473804\n",
      "KP0228_02051,16.780148994355134\n",
      "KP0228_03719,15.044282982810538\n",
      "KP0228_00159,-14.794937432144755\n",
      "KP0228_04120,14.25906212636767\n",
      "KP0228_04079,13.615277125936435\n",
      "KP0228_01191,-13.250081288477007\n",
      "KP0228_03852,-13.061903282336951\n",
      "KP0228_00250,-12.702913142216595\n",
      "KP0228_00231,12.480885373345659\n",
      "KP0228_04054,12.412976149185031\n",
      "KP0228_03775,-12.344486449884771\n",
      "KP0228_01648,12.059174551541314\n",
      "KP0228_03994,11.391855124738898\n",
      "KP0228_03168,-10.945382544331428\n",
      "KP0228_04594,10.768923990846394\n",
      "KP0228_03382,-10.506466349920101\n",
      "KP0228_01223,10.241681294787082\n",
      "KP0228_04429,-10.207391452485144\n",
      "KP0228_04647,-9.889848714894582\n",
      "KP0228_00591,9.679951781058403\n",
      "KP0228_00700,-9.336872593419118\n",
      "KP0228_05018,8.568195358692085\n",
      "KP0228_00230,-8.303072452955409\n",
      "KP0228_04175,8.30041650776661\n",
      "KP0228_00063,7.52266940784179\n",
      "KP0228_02747,-7.347975528837725\n",
      "KP0228_00089,7.18636111295361\n",
      "KP0228_00935,-6.95647844825859\n",
      "KP0228_01623,-6.464227033539828\n",
      "KP0228_04384,-6.375683862621158\n",
      "KP0228_01448,-5.995076215667183\n",
      "KP0228_04994,-5.848607558413882\n",
      "KP0228_04845,5.71293265822936\n",
      "KP0228_03378,5.523923259959511\n",
      "KP0228_03229,5.410664543428924\n",
      "KP0228_00943,5.365479311376306\n",
      "KP0228_04612,-5.093367127580888\n",
      "KP0228_01206,-5.037978864213736\n",
      "KP0228_02039,-5.00506672196372\n",
      "KP0228_02041,-4.87486152817607\n",
      "KP0228_02534,4.865412163146921\n",
      "KP0228_03718,4.79278876799354\n",
      "KP0228_00304,-4.738893701312986\n",
      "KP0228_04293,-4.300242800984468\n",
      "KP0228_02212,4.243358707162233\n",
      "KP0228_04468,4.189080872944728\n",
      "KP0228_04206,4.089892453598774\n",
      "KP0228_00239,4.085399593815444\n",
      "KP0228_00179,4.050410657238713\n",
      "KP0228_03154,-3.956593195947193\n",
      "KP0228_03166,-3.871666146308956\n",
      "KP0228_04904,3.8610328760488972\n",
      "KP0228_02409,3.721591433414904\n",
      "KP0228_03875,-3.7079309929357467\n",
      "KP0228_03370,3.6177148537969344\n",
      "KP0228_03995,-3.6126035294542063\n",
      "KP0228_01881,3.566998862383659\n",
      "KP0228_04064,-3.540897390324735\n",
      "KP0228_02221,3.5055225868003137\n",
      "KP0228_03273,-3.4858391570324683\n",
      "KP0228_04007,-3.4538069668411135\n",
      "KP0228_00733,-3.4283916611550853\n",
      "KP0228_02559,3.327079253597284\n",
      "KP0228_00590,3.280444057286238\n",
      "KP0228_02317,-3.251188144072955\n",
      "KP0228_03593,-3.2322323851020536\n",
      "KP0228_00827,3.1084167891851906\n",
      "KP0228_01637,3.016083437454786\n",
      "KP0228_04835,2.992937131446031\n",
      "KP0228_00801,2.8265828368003\n",
      "KP0228_00799,-2.807133212278619\n",
      "KP0228_00398,-2.791426313414855\n",
      "KP0228_02388,-2.73601234442038\n",
      "KP0228_00885,-2.6750440587120528\n",
      "KP0228_00787,2.529363443438597\n",
      "KP0228_03380,-2.3732133937521387\n",
      "KP0228_05019,2.2199954646708977\n",
      "KP0228_04292,-2.1873759497970022\n",
      "KP0228_03486,2.1050004422152444\n",
      "KP0228_00390,2.100843227980202\n",
      "KP0228_01639,2.0865302481880392\n",
      "KP0228_00798,2.037028604342625\n",
      "KP0228_03901,2.0068623416848785\n",
      "KP0228_04305,1.9936733941861622\n",
      "KP0228_00813,1.9753454132502877\n",
      "KP0228_03372,-1.9331528057498069\n",
      "KP0228_04532,-1.8705942348230222\n",
      "KP0228_04168,1.8543574386590953\n",
      "KP0228_00228,-1.8395603661371833\n",
      "KP0228_03419,1.8311458846172812\n",
      "KP0228_00318,-1.8056901836896746\n",
      "KP0228_00945,1.7919262385214378\n",
      "KP0228_02672,1.7606811116097378\n",
      "KP0228_03173,-1.7529526367289492\n",
      "KP0228_00995,1.6976052426905506\n",
      "KP0228_00656,1.6859452240032122\n",
      "KP0228_04911,-1.6820529171418068\n",
      "KP0228_03192,-1.6616486295279926\n",
      "KP0228_00302,-1.6474708064014834\n",
      "KP0228_04943,-1.6473707604259502\n",
      "KP0228_00229,1.589600376169998\n",
      "KP0228_04701,-1.58664110061904\n",
      "KP0228_04315,1.5772941949696753\n",
      "KP0228_04573,1.5676313141786142\n",
      "KP0228_01052,1.5319060641802749\n",
      "KP0228_00384,1.4785137519008147\n",
      "KP0228_02442,1.4465415030422897\n",
      "KP0228_00831,-1.4458322365971792\n",
      "KP0228_00256,1.4224990381108955\n",
      "KP0228_02223,-1.4210406195147027\n",
      "KP0228_03771,-1.3970245748497923\n",
      "KP0228_00828,1.3824623987300038\n",
      "KP0228_04432,1.3684045564799838\n",
      "KP0228_02357,-1.3218756665728255\n",
      "KP0228_04298,-1.2926564786566428\n",
      "KP0228_02342,1.2876254926545898\n",
      "KP0228_03233,-1.2596905170949426\n",
      "KP0228_00227,-1.2483195168753585\n",
      "KP0228_02890,1.2123393929114477\n",
      "KP0228_03241,-1.1935228535455609\n",
      "KP0228_04031,1.1353340914489995\n",
      "KP0228_02674,-1.1311370320010696\n",
      "KP0228_00134,-1.1079092955556298\n",
      "KP0228_00532,1.0889848028625009\n",
      "KP0228_02477,-1.0583437490084007\n",
      "KP0228_01412,-1.0580280287997064\n",
      "KP0228_03536,0.9966993304599695\n",
      "KP0228_00864,0.9902920454462548\n",
      "KP0228_03164,-0.970143099159191\n",
      "KP0228_02232,0.8772720457087234\n",
      "KP0228_00838,-0.865616489495923\n",
      "KP0228_03004,0.8067829355152363\n",
      "KP0228_04440,-0.800255741873549\n",
      "KP0228_03346,-0.7829417618616795\n",
      "KP0228_03625,-0.769769504115931\n",
      "KP0228_03109,0.7667948822875362\n",
      "KP0228_00108,-0.7638372434056165\n",
      "KP0228_00755,-0.7631809451707681\n",
      "KP0228_04113,-0.7340625991206824\n",
      "KP0228_01339,-0.7222012930181376\n",
      "KP0228_05223,0.7169146095185354\n",
      "KP0228_03556,0.6905786706669171\n",
      "KP0228_00841,0.6762571113651679\n",
      "KP0228_00791,-0.6133463456427706\n",
      "KP0228_02065,-0.611593152062572\n",
      "KP0228_04446,-0.6029124396011797\n",
      "KP0228_04568,-0.5585842095918472\n",
      "KP0228_00446,0.5575039987512328\n",
      "KP0228_00367,-0.5410154844173326\n",
      "KP0228_00074,-0.5254058312248215\n",
      "KP0228_03020,-0.522106206046189\n",
      "KP0228_03428,0.5067570865544524\n",
      "KP0228_03031,-0.5058038733740585\n",
      "KP0228_00386,0.4934047055681713\n",
      "KP0228_00891,0.4927004361511349\n",
      "KP0228_04388,-0.4723294562895025\n",
      "KP0228_02626,0.4457878156098286\n",
      "KP0228_00823,0.4304763623807961\n",
      "KP0228_00963,0.428675443655432\n",
      "KP0228_05291,-0.42009289124158383\n",
      "KP0228_00652,0.4111184232657293\n",
      "KP0228_03596,0.39131636201485\n",
      "KP0228_00704,-0.3846511441191855\n",
      "KP0228_03445,-0.3842965782063716\n",
      "KP0228_03364,-0.37413089663297505\n",
      "KP0228_03073,0.366245693423325\n",
      "KP0228_03517,0.3535961515339982\n",
      "KP0228_04395,-0.3499990203742801\n",
      "KP0228_03361,0.32199175060839197\n",
      "KP0228_04302,-0.3162982391075818\n",
      "KP0228_04490,0.3086879609580708\n",
      "KP0228_03762,0.30196729649151727\n",
      "KP0228_04130,0.2893800675844291\n",
      "KP0228_00994,0.2844978883278437\n",
      "KP0228_01233,0.27838694513999146\n",
      "KP0228_01656,0.2756653618770933\n",
      "KP0228_05205,0.26154195355857224\n",
      "KP0228_01089,-0.23357698374538494\n",
      "KP0228_04207,-0.20178762552069499\n",
      "KP0228_05045,-0.18012991274011342\n",
      "KP0228_04196,0.17357661550421644\n",
      "KP0228_02616,0.1598359822737318\n",
      "KP0228_00770,-0.15970464831516032\n",
      "KP0228_03052,0.15712484115142447\n",
      "KP0228_04336,-0.13942934729368062\n",
      "KP0228_04579,-0.1354828710856843\n",
      "KP0228_00806,-0.13022645025264448\n",
      "KP0228_02745,0.12222779349816096\n",
      "KP0228_01268,0.09651237853974191\n",
      "KP0228_02541,-0.09616693075072842\n",
      "KP0228_00740,-0.09061275423371412\n",
      "KP0228_04033,-0.08976501431583246\n",
      "KP0228_02598,0.0791931666594127\n",
      "KP0228_04367,0.07138235023275641\n",
      "KP0228_05090,-0.06176096751183491\n",
      "KP0228_04882,-0.06014065874540839\n",
      "KP0228_02213,0.04829798303830036\n",
      "KP0228_03914,0.04311581383411741\n",
      "KP0228_00923,-0.027465728857459064\n",
      "KP0228_00941,-0.024817414226194042\n",
      "KP0228_02685,0.003246910407289766\n",
      "KP0228_03920,-0.00017987216083136402\n"
     ]
    }
   ],
   "source": [
    "modelName = \"logistic\"\n",
    "assert modelName in [\"randomForest\", \"GBTC\", \"logistic\", \"SVC\"], \"invalid model name.\"\n",
    "##################################################\n",
    "#######################NOTE#######################\n",
    "##################################################\n",
    "# Be sure that the dataPath and dataSetOfInterest\n",
    "# correspond to the same dataset used to train the\n",
    "# models\n",
    "dataSetOfInterest = \"dataset_1_\"\n",
    "dataPath = \"data/featureImportanceTestData/dataset_1_full.csv\"\n",
    "modelDict = allDataModelDict[dataSetOfInterest][modelName]\n",
    "bestModel = modelDict[\"gridcv\"].best_estimator_\n",
    "featureTransformer = bestModel.steps[0][1]# 0th step is the feature extraction, and the first element\n",
    "# of that is the actual function for it. \n",
    "\n",
    "\n",
    "\n",
    "isolateList = []\n",
    "with open(dataPath) as fp:\n",
    "    csvReader = csv.reader(fp)\n",
    "    header = next(csvReader)\n",
    "if len(header) > 100000:\n",
    "    print(\"Reading large data with more efficient code\")\n",
    "    with open(dataPath) as fp:\n",
    "        csvReader = csv.reader(fp)\n",
    "        header = next(csvReader)\n",
    "        for line in csvReader:\n",
    "            isolateList.append(line[0])\n",
    "    df = np.loadtxt(dataPath, delimiter = \",\", skiprows = 1, usecols = range(1, len(header))) \n",
    "    df = pd.DataFrame(df, columns = header[1:])\n",
    "    df.insert(loc = 0, column = \"isolate\", value = isolateList) \n",
    "else:\n",
    "    df = pd.read_csv(dataPath)\n",
    "\n",
    "\n",
    "\n",
    "df = df.set_index(\"isolate\")\n",
    "X_df = df.drop(labels = [\"pbr_res\"], axis = 1)\n",
    "X = X_df.values\n",
    "allFeatureNames = np.array(list(X_df))\n",
    "chosenFeatures = allFeatureNames[[featureTransformer.transform(np.arange(X.shape[1]).reshape([1, X.shape[1]]))]]\n",
    "chosenFeatures = chosenFeatures[0]\n",
    "\n",
    "\n",
    "if modelName == \"randomForest\":\n",
    "    # Random forest had a bit of a naming mishap where I switched from\n",
    "    # RFC to randomForest\n",
    "    bestModelParams = bestModel.get_params()[\"RFC\"]\n",
    "else:\n",
    "    bestModelParams = bestModel.get_params()[modelName]\n",
    "    \n",
    "    \n",
    "if modelName == \"GBTC\":\n",
    "    print(\"feature importance for GBTC\")\n",
    "    featureImportance = bestModelParams.feature_importances_\n",
    "elif modelName == \"randomForest\":\n",
    "    print(\"feature importance for random forest\")\n",
    "\n",
    "    featureImportance = bestModelParams.feature_importances_\n",
    "elif modelName == \"logistic\":\n",
    "    print(\"Feature importance logistic\")\n",
    "    featureImportance = bestModelParams.coef_[0]\n",
    "elif modelName == \"SVC\":\n",
    "    if bestModel[\"SVC\"].kernel != \"linear\":\n",
    "        print(\"no coefficients are available for SVC without a linear kernel\\n\",\n",
    "             \"This SVC's kernel is {}\".format(bestModel[\"SVC\"].kernel))\n",
    "        assert False, \"Breaking the code because we can't get feature importance here\"\n",
    "else:\n",
    "    assert False, \"Model name: {} not implemented for feature importance\".format(modelName)\n",
    "\n",
    "featureImportanceDict = defaultdict(int) # features and coefficients line up\n",
    "# but because there can be repeated features for logistic regression this needs to be \n",
    "# added together.\n",
    "for feat, imp in zip(chosenFeatures, featureImportance):\n",
    "    featureImportanceDict[feat] += imp\n",
    "\n",
    "nNonZeroFeats = 0\n",
    "for _, imp in featureImportanceDict.items():\n",
    "    if imp != 0.0:\n",
    "        nNonZeroFeats += 1\n",
    "featureImportanceTupleList = sorted(featureImportanceDict.items(),\n",
    "                                   key=lambda p:np.abs(p[1]), reverse = True)# sorting list    \n",
    "\n",
    "\n",
    "print(\"{} features before feature selection\".format(len(allFeatureNames)))\n",
    "print(\"{} features passed to this model\".format(len(chosenFeatures))) # for logistic\n",
    "print(\"{} unique features passed to this model\".format(len(set(chosenFeatures)))) # for logistic\n",
    "print(\"{} features given feature importance above 0\\n\".format(nNonZeroFeats))\n",
    "\n",
    "print(\"SANITY CHECK. This is the best model being used. Please be sure that\",\n",
    "     \"The parameters match up with the model you specified. Sometimes an old model\",\n",
    "     \"Can be used by accident if the kernel is not restarted\\n\\n\",\n",
    "      bestModel[modelName] if modelName != 'randomForest' else bestModel[\"RFC\"],\n",
    "     \"\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"human readable feature importance\")\n",
    "for feature, importanceMeasure in featureImportanceTupleList:\n",
    "    if importanceMeasure != 0.0:\n",
    "        print(\"Feature {} coefficient/importance {}\\n\".format(feature, importanceMeasure))\n",
    "\n",
    "\n",
    "        \n",
    "print(\"Printing feature importance so it can be copied into a csv file\")\n",
    "print(\"featureName,importanceMetric\")\n",
    "for feature, importanceMeasure in featureImportanceTupleList:\n",
    "    if importanceMeasure != 0.0:\n",
    "        print(\"{},{}\".format(feature, importanceMeasure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMR_ML] *",
   "language": "python",
   "name": "conda-env-AMR_ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
