{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score,\\\n",
    "    f1_score, balanced_accuracy_score, roc_auc_score, accuracy_score\n",
    "import pickle\n",
    "from src.mlPipeline.plotting import findBestModelPerDataset\n",
    "import glob\n",
    "import copy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pkl_path_17_18 = \"data/oli_gwas_cross_validation/modelDictMultiDataRun_dataset_17_18_20190813.pkl\"\n",
    "with open(model_pkl_path_17_18, \"rb\") as pklFile:\n",
    "    model_dict_17_18 = pickle.load(pklFile)\n",
    "model_pkl_path_19_20_21 = \"data/oli_gwas_cross_validation/modelDictMultiDataRun_dataset_19_20_21_20190813.pkl\"\n",
    "with open(model_pkl_path_19_20_21, \"rb\") as pklFile:\n",
    "    model_dict_19_20_21 = pickle.load(pklFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_prefix_list_1 = ['dataset_17_', 'dataset_18_']\n",
    "dataset_prefix_list_2 = ['dataset_19_', 'dataset_20_', 'dataset_21_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_data(data_path):\n",
    "        trainPath = data_path  + \"_train.csv\"\n",
    "        valPath = data_path  + \"_test.csv\"\n",
    "        gwasPath = data_path  + \"_gwas.csv\"\n",
    "        trainDF = pd.read_csv(trainPath)\n",
    "        valDF = pd.read_csv(valPath)\n",
    "        allData = pd.concat([trainDF, valDF])\n",
    "        GWASDF = pd.read_csv(gwasPath)\n",
    "        nTrain = trainDF.shape[0]\n",
    "        nVal = valDF.shape[0]\n",
    "        trainDF = trainDF.set_index(\"isolate\")\n",
    "        valDF = valDF.set_index(\"isolate\")\n",
    "        return(trainDF, valDF, GWASDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running dataset: dataset_17_, with model_dict for datasets: 17-18\n",
      "running dataset: dataset_18_, with model_dict for datasets: 17-18\n",
      "running dataset: dataset_19_, with model_dict for datasets: 19-20-21\n",
      "running dataset: dataset_20_, with model_dict for datasets: 19-20-21\n",
      "running dataset: dataset_21_, with model_dict for datasets: 19-20-21\n"
     ]
    }
   ],
   "source": [
    "dataset_model_bootstrap_performance_dict = defaultdict(dict)\n",
    "\n",
    "for dataset_prefix_list in [dataset_prefix_list_1, dataset_prefix_list_2]:\n",
    "    for dataset_prefix in dataset_prefix_list:\n",
    "        if dataset_prefix in dataset_prefix_list_1:\n",
    "            model_dict_all = model_dict_17_18\n",
    "            model_dict_id = \"17-18\"\n",
    "        else:\n",
    "            model_dict_all = model_dict_19_20_21\n",
    "            model_dict_id = \"19-20-21\"\n",
    "        print(\"running dataset: {}, with model_dict for datasets: {}\".format(dataset_prefix, model_dict_id))\n",
    "        for model_name, model_dict in model_dict_all[dataset_prefix].items():\n",
    "            best_model = copy.deepcopy(model_dict[\"gridcv\"].best_estimator_)\n",
    "            for data_idx in range(0,10):\n",
    "                data_path = \"data/oli_gwas_cross_validation/\" + \\\n",
    "                    dataset_prefix[:-1] + \".{}\".format(data_idx)\n",
    "                # Read in all data\n",
    "                trainDF, valDF, gwasDF = read_in_data(data_path)\n",
    "                # Split training a testing matrices\n",
    "                X_train = trainDF.drop(labels = [\"pbr_res\"], axis = 1).values\n",
    "                Y_train = trainDF[\"pbr_res\"].values\n",
    "                X_val = valDF.drop(labels = [\"pbr_res\"], axis = 1).values\n",
    "                Y_val = valDF[\"pbr_res\"].values\n",
    "                # Refit model\n",
    "                best_model.fit(X_train, Y_train)\n",
    "                # Get metrics\n",
    "                preds = best_model.predict(X_val)\n",
    "                if model_name == \"SVC\" and not best_model.steps[1][1].probability:\n",
    "                    scores = None\n",
    "                    rocauc = None\n",
    "                else:\n",
    "                    scores = best_model.predict_proba(X_val)\n",
    "                    rocauc = roc_auc_score(y_true = Y_val, y_score = scores[:,1])\n",
    "                f1 = f1_score(y_true = Y_val, y_pred = preds)\n",
    "                prec = precision_score(y_true = Y_val, y_pred = preds)\n",
    "                rec = recall_score(y_true = Y_val, y_pred = preds)        \n",
    "                bal_acc = balanced_accuracy_score(y_true = Y_val, y_pred = preds)\n",
    "                acc = accuracy_score(y_true = Y_val, y_pred = preds)\n",
    "                dataset_model_bootstrap_performance_dict\\\n",
    "                    [dataset_prefix + model_name][\"f1_{}\".format(data_idx)] = f1\n",
    "                dataset_model_bootstrap_performance_dict\\\n",
    "                    [dataset_prefix + model_name][\"prec_{}\".format(data_idx)] = prec\n",
    "                dataset_model_bootstrap_performance_dict\\\n",
    "                    [dataset_prefix + model_name][\"rec_{}\".format(data_idx)] = rec\n",
    "                dataset_model_bootstrap_performance_dict\\\n",
    "                    [dataset_prefix + model_name][\"balanced_acc_{}\".format(data_idx)] = bal_acc\n",
    "                dataset_model_bootstrap_performance_dict\\\n",
    "                    [dataset_prefix + model_name][\"acc_{}\".format(data_idx)] = acc\n",
    "                dataset_model_bootstrap_performance_dict\\\n",
    "                    [dataset_prefix + model_name][\"rocauc_{}\".format(data_idx)] = rocauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"data/oli_gwas_cross_validation/bootstrap_results.csv\"\n",
    "results_df = pd.DataFrame.from_dict(dataset_model_bootstrap_performance_dict, orient = \"index\")\n",
    "results_df.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMR_ML] *",
   "language": "python",
   "name": "conda-env-AMR_ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
